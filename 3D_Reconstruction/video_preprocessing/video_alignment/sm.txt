## 方法要点与为何有效

### 1  ROI + 深度场景

对只含吊索的中央带做光流，剔除了两侧远景/近景错位导致的位移幅度差异 ([Medium][1])。

### 2  Lucas-Kanade 光流

LK 在特征点周围做梯度匹配，能给出亚像素级位移；对于密集上移（或下移）场景，所有 dy 会同向增大，适合取中位数作全局量度 ([learnopencv.com][2], [PyImageSearch][3])。

### 3  自适应阈值

现场噪声（灯闪、行人影子）通过初期统计自动量化；“μ+3σ” 属于经典异常检测阈值 ([learnopencv.com][4], [MDPI][5])。

### 4  连续帧确认

连续 `CONSEC_FRAMES` 条件避免偶发值误触；实现类似滑动窗口置信度过滤 ([Stack Overflow][6])。

---

## 进一步可调

* **点不足时重检测** – 代码已在特征点 < 100 时自动重新检测，防止跟踪漂移 ([answers.opencv.org][7], [nghiaho.com][8])。
* **镜头横向抖动** – 若画面有轻微左右摇，可对 `np.abs(dy)` 再减去 `np.abs(dx)` 加权，突出纯垂直量 ([Stack Overflow][9])。
* **低帧率视频** – 对 25 fps 视频可把 `CONSEC_FRAMES` 改为 2-3 帧，保证及时触发。
